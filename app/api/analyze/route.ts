import { NextRequest, NextResponse } from 'next/server'

// Mock face analysis function
function analyzeFace(imageData: string) {
  const emotions = ['happy', 'sad', 'angry', 'surprise', 'neutral', 'fear', 'disgust']
  const genders = ['Man', 'Woman']
  const races = ['asian', 'indian', 'black', 'white', 'middle eastern', 'latino hispanic']
  
  return {
    emotion: emotions[Math.floor(Math.random() * emotions.length)],
    age: Math.floor(Math.random() * 60) + 15,
    gender: genders[Math.floor(Math.random() * genders.length)],
    race: races[Math.floor(Math.random() * races.length)]
  }
}

function generateMalayalamStatus(analysis: any) {
  const funnyTexts: string[] = []
  
  // Emotion-based status
  switch (analysis.emotion) {
    case 'happy':
      funnyTexts.push("‡¥á‡¥®‡µç‡¥®‡µç ‡¥ï‡¥≤‡µç‡¥Ø‡¥æ‡¥£‡¥Ç ‡¥ï‡¥æ‡¥£‡¥æ‡µª ‡¥™‡µã‡¥Ø‡¥æ‡¥≤‡µã? üòÑ")
      break
    case 'sad':
      funnyTexts.push("‡¥§‡¥≥‡µç‡¥≥‡¥ø‡¥™‡µç‡¥™‡µã‡¥Ø‡¥ø ‡¥Ö‡¥≤‡µç‡¥≤‡µá? üò¢")
      break
    case 'angry':
      funnyTexts.push("‡¥Ü‡¥∞‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡¥≤‡µÅ‡¥Ç ‡¥µ‡¥¥‡¥ï‡µç‡¥ï‡µç ‡¥™‡¥±‡¥û‡µç‡¥û‡µã? üò†")
      break
    case 'surprise':
      funnyTexts.push("‡¥é‡¥®‡µç‡¥§‡µã ‡¥µ‡¥≤‡¥ø‡¥Ø ‡¥ï‡¥æ‡¥∞‡µç‡¥Ø‡¥Ç ‡¥ï‡µá‡¥ü‡µç‡¥ü‡µã? üò≤")
      break
    case 'neutral':
      funnyTexts.push("‡¥é‡¥®‡µç‡¥§‡µã ‡¥ö‡¥ø‡¥®‡µç‡¥§‡¥Ø‡¥ø‡µΩ ‡¥Ü‡¥£‡¥≤‡µç‡¥≤‡µã ü§î")
      break
    case 'fear':
      funnyTexts.push("‡¥é‡¥®‡µç‡¥§‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡¥≤‡µÅ‡¥Ç ‡¥™‡µá‡¥ü‡¥ø‡¥ö‡µç‡¥ö‡µã? üò®")
      break
    default:
      funnyTexts.push("‡¥®‡¥≤‡µç‡¥≤ ‡¥≤‡µÅ‡¥ï‡µç‡¥ï‡µç ‡¥Ü‡¥£‡¥≤‡µç‡¥≤‡µã! üòä")
  }
  
  // Age-based status
  if (analysis.age < 18) {
    funnyTexts.push("‡¥∏‡µç‡¥ï‡µÇ‡µæ ‡¥Ø‡µÇ‡¥£‡¥ø‡¥´‡µã‡¥Ç ‡¥µ‡µÜ‡¥ö‡µç‡¥ö‡¥ø‡¥ü‡µç‡¥ü‡µÅ‡¥£‡µç‡¥ü‡¥≤‡µç‡¥≤‡µã üéí")
  } else if (analysis.age >= 18 && analysis.age <= 25) {
    funnyTexts.push("‡¥ï‡µã‡¥≥‡µá‡¥ú‡µç ‡¥¨‡¥ô‡µç‡¥ï‡µç ‡¥Ö‡¥ü‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥® ‡¥∞‡µÇ‡¥™‡¥Ç üéì")
  } else if (analysis.age > 25 && analysis.age <= 35) {
    funnyTexts.push("‡¥ú‡µã‡¥¨‡¥ø‡¥®‡µç‡¥±‡µÜ ‡¥ü‡µÜ‡µª‡¥∑‡µª ‡¥â‡¥£‡µç‡¥ü‡¥≤‡µç‡¥≤‡µã üíº")
  } else {
    funnyTexts.push("‡¥Ö‡¥®‡µÅ‡¥≠‡¥µ‡¥∏‡¥Æ‡µç‡¥™‡¥®‡µç‡¥®‡µª ‡¥Ü‡¥£‡¥≤‡µç‡¥≤‡µã üë®‚Äçü¶≥")
  }
  
  // Gender-based status
  if (analysis.gender === 'Man') {
    funnyTexts.push("‡¥¨‡µÜ‡¥µ‡µç‡¥µ‡µç ‡¥â‡¥£‡µç‡¥ü‡¥æ‡¥ï‡µÅ‡¥Ç ‡¥á‡¥§‡µç‡¥∞‡¥Ø‡µÅ‡¥Ç ‡¥∏‡µç‡¥±‡µç‡¥±‡µà‡¥≤‡¥ø‡¥∑‡µç ‡¥Ü‡¥£‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ! üï∫")
  } else {
    funnyTexts.push("‡¥ï‡µÅ‡¥ü‡µç‡¥ü‡¥ø ‡¥û‡¥æ‡µª ‡¥í‡¥®‡µç‡¥®‡µÅ‡¥Ç ‡¥™‡¥±‡¥Ø‡¥ø‡¥≤‡µç‡¥≤ üòú")
  }
  
  return funnyTexts
}

// Generate a simple audio tone as base64 (mock TTS)
function generateMockAudio(): string {
  // Create a simple WAV file header + tone data
  const sampleRate = 22050
  const duration = 2 // 2 seconds
  const samples = sampleRate * duration
  const buffer = new ArrayBuffer(44 + samples * 2)
  const view = new DataView(buffer)
  
  // WAV header
  const writeString = (offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i))
    }
  }
  
  writeString(0, 'RIFF')
  view.setUint32(4, 36 + samples * 2, true)
  writeString(8, 'WAVE')
  writeString(12, 'fmt ')
  view.setUint32(16, 16, true)
  view.setUint16(20, 1, true)
  view.setUint16(22, 1, true)
  view.setUint32(24, sampleRate, true)
  view.setUint32(28, sampleRate * 2, true)
  view.setUint16(32, 2, true)
  view.setUint16(34, 16, true)
  writeString(36, 'data')
  view.setUint32(40, samples * 2, true)
  
  // Generate simple tone
  for (let i = 0; i < samples; i++) {
    const sample = Math.sin(2 * Math.PI * 440 * i / sampleRate) * 0.3
    view.setInt16(44 + i * 2, sample * 32767, true)
  }
  
  // Convert to base64
  const bytes = new Uint8Array(buffer)
  let binary = ''
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i])
  }
  return btoa(binary)
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { image } = body
    
    if (!image) {
      return NextResponse.json(
        { error: 'No image provided' },
        { status: 400 }
      )
    }
    
    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 1500))
    
    // Analyze the face (mock implementation)
    const analysis = analyzeFace(image)
    
    // Generate funny Malayalam text
    const funnyTexts = generateMalayalamStatus(analysis)
    
    // Generate mock audio
    const audioBase64 = generateMockAudio()
    
    return NextResponse.json({
      funny_text: funnyTexts,
      voice: audioBase64,
      analysis: analysis
    })
    
  } catch (error) {
    console.error('Analysis error:', error)
    return NextResponse.json(
      { error: 'Failed to analyze image' },
      { status: 500 }
    )
  }
}
